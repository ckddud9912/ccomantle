import fasttext
import json
import re
import numpy as np
from sklearn.decomposition import PCA
import os

# ğŸ”¥ FastText ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = r"C:\Users\ì°½ì˜\Desktop\cc.ko.300.bin"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # src í´ë” ê¸°ì¤€
DATA_PATH = os.path.join(BASE_DIR, "..", "data")

# ğŸ”¹ ì¶œë ¥ íŒŒì¼
OUTPUT_FILE = DATA_PATH + "/embedding_dictionary.json"

# ğŸ”¹ top-k í•„í„°ë§ (ì˜ˆ: 50,000ê°œ)
TOP_K = 50000

# ğŸ”¹ ë‹¨ì–´ í•„í„° ì¡°ê±´
MIN_LEN = 2
MAX_LEN = 5

def is_korean(word):
    return re.search(r"[ê°€-í£]", word) is not None

def main():
    print("ğŸ”µ FastText ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = fasttext.load_model(MODEL_PATH)
    print("âœ” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    print("ğŸ”µ ë‹¨ì–´ í›„ë³´ ì¶”ì¶œ ì¤‘...")
    words = model.get_words()
    valid = [w for w in words if MIN_LEN <= len(w) <= MAX_LEN and is_korean(w)]
    print(f"í•œêµ­ì–´ í›„ë³´ ë‹¨ì–´: {len(valid)}ê°œ")

    # top-k ë‹¨ì–´ ì„ íƒ
    final_words = valid[:TOP_K]
    print(f"âœ” ìµœì¢… {TOP_K}ê°œ ë‹¨ì–´ ì„ íƒ ì™„ë£Œ")

    print("ğŸ”µ FastText ë²¡í„° ìƒì„± ì¤‘...")
    vectors = np.array([model.get_word_vector(w) for w in final_words], dtype=np.float32)
    print(f"ë²¡í„° ìƒì„± ì™„ë£Œ: shape={vectors.shape}")

    print("ğŸ”µ PCA ì°¨ì› ì¶•ì†Œ (ì›í•˜ë©´ ì°¨ì› ë³€ê²½ ê°€ëŠ¥)")
    pca = PCA(n_components=128, random_state=42)
    vectors_reduced = pca.fit_transform(vectors)
    print(f"PCA ì™„ë£Œ: shape={vectors_reduced.shape}")

    print("ğŸ”µ L2 ì •ê·œí™”")
    norms = np.linalg.norm(vectors_reduced, axis=1, keepdims=True)
    vectors_normalized = vectors_reduced / norms
    print("âœ” ì •ê·œí™” ì™„ë£Œ")

    # ğŸ”¹ embedding_dictionary.json ìƒì„±
    emb_dict = {w: vec.tolist() for w, vec in zip(final_words, vectors_normalized)}
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(emb_dict, f, ensure_ascii=False, indent=2)
    print(f"ğŸ‰ {OUTPUT_FILE} ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()
