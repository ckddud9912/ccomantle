# ---- ë³µë¶™ ì‹œì‘ ----
import os
import gzip
import shutil
import requests
import numpy as np

# FastText í•œêµ­ì–´ ë²¡í„° (Facebook ê³µì‹)
VECTOR_URL = "https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.vec.gz"
VECTOR_GZ = "cc.ko.300.vec.gz"
VECTOR_FILE = "cc.ko.300.vec"

word_vectors: dict[str, np.ndarray] = {}
_loaded = False

_answer_cache = None
_sims_cache = None  # list[(word, raw_sim)]
_ranking_cache = None  # dict[word, rank]


def _download_vectors():
    print("ğŸ“¥ FastText ë²¡í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    resp = requests.get(VECTOR_URL, stream=True)
    resp.raise_for_status()
    with open(VECTOR_GZ, "wb") as f:
        for chunk in resp.iter_content(chunk_size=1024 * 1024):
            if chunk:
                f.write(chunk)
    print("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:", VECTOR_GZ)


def _extract_vectors():
    print("ğŸ§© FastText ë²¡í„° ì••ì¶• í•´ì œ ì¤‘...")
    with gzip.open(VECTOR_GZ, "rb") as f_in, open(VECTOR_FILE, "wb") as f_out:
        shutil.copyfileobj(f_in, f_out)
    print("ğŸ§© ì••ì¶• í•´ì œ ì™„ë£Œ:", VECTOR_FILE)
    try:
        os.remove(VECTOR_GZ)
    except OSError:
        pass


def _ensure_vectors_ready():
    if not os.path.exists(VECTOR_FILE):
        if not os.path.exists(VECTOR_GZ):
            _download_vectors()
        _extract_vectors()


def load_fasttext():
    """cc.ko.300.vec ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼ (ì²« í˜¸ì¶œë§Œ ì˜¤ë˜ ê±¸ë¦¼)."""
    global _loaded, word_vectors
    if _loaded:
        return

    _ensure_vectors_ready()

    print("ğŸ”§ FastText ë²¡í„° ë¡œë”© ì‹œì‘...")
    with open(VECTOR_FILE, "r", encoding="utf-8", errors="ignore") as f:
        header = f.readline()
        for line in f:
            parts = line.rstrip().split(" ")
            if len(parts) < 302:
                continue
            w = parts[0]
            vec = np.asarray(parts[1:], dtype=np.float32)
            word_vectors[w] = vec

    _loaded = True
    print("âœ… FastText ë¡œë”© ì™„ë£Œ. ë‹¨ì–´ ìˆ˜:", len(word_vectors))


def has_word(word: str) -> bool:
    return word in word_vectors


def get_vector(word: str) -> np.ndarray | None:
    return word_vectors.get(word)


def cosine_sim(v1: np.ndarray, v2: np.ndarray) -> float:
    dot = float(np.dot(v1, v2))
    norm = float(np.linalg.norm(v1) * np.linalg.norm(v2))
    return dot / norm if norm > 0 else 0.0


def convert_similarity(sim: float) -> float:
    """
    Raw cosine ìœ ì‚¬ë„(sim, ëŒ€ëµ 0.2~0.8)ë¥¼
    ê¼¬ë§¨í‹€ ëŠë‚Œìœ¼ë¡œ -20 ~ +70 ì ìˆ˜ë¡œ ë³€í™˜
    """
    scaled = ((sim - 0.2) / 0.6) * 90.0 - 20.0
    if scaled < -20:
        scaled = -20
    if scaled > 70:
        scaled = 70
    return round(float(scaled), 2)


def calculate_ranking(answer_word: str):
    """
    ì •ë‹µ ê¸°ì¤€ ì „ì²´ ë‹¨ì–´ ìœ ì‚¬ë„ ìˆœìœ„ ê³„ì‚°.
    """
    global _answer_cache, _sims_cache, _ranking_cache

    load_fasttext()

    if _answer_cache == answer_word and _sims_cache is not None:
        return _sims_cache, _ranking_cache

    answer_vec = word_vectors[answer_word]
    sims = []

    print("ğŸ“Š ì „ì²´ ë‹¨ì–´ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘... (ì‹œê°„ ì†Œìš”)")
    for w, vec in word_vectors.items():
        s = cosine_sim(vec, answer_vec)
        sims.append((w, s))

    sims.sort(key=lambda x: x[1], reverse=True)
    ranking = {w: idx + 1 for idx, (w, _) in enumerate(sims)}

    _answer_cache = answer_word
    _sims_cache = sims
    _ranking_cache = ranking

    print("ğŸ ìˆœìœ„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
    return sims, ranking


def stats_for_answer(answer_word: str):
    """
    ì •ë‹µ ê¸°ì¤€:
      - ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´
      - 10ë²ˆì§¸ ìœ ì‚¬í•œ ë‹¨ì–´
      - 1000ë²ˆì§¸ ìœ ì‚¬í•œ ë‹¨ì–´
    í™˜ì‚° ì ìˆ˜ ë¦¬í„´
    """
    sims, _ = calculate_ranking(answer_word)
    filtered = [item for item in sims if item[0] != answer_word]

    def get_k(k: int):
        if len(filtered) >= k:
            return convert_similarity(filtered[k - 1][1])
        return None

    max_sim = get_k(1)
    top10_sim = get_k(10)
    top1000_sim = get_k(1000)
    return max_sim, top10_sim, top1000_sim
# ---- ë³µë¶™ ë ----
